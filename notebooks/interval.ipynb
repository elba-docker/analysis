{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add analysis to the path\n",
    "import sys\n",
    "import pathlib\n",
    "parent_dir = os.path.join(os.path.abspath(''), \"..\")\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import parsers\n",
    "from pprint import pprint\n",
    "from aggregation import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import portion\n",
    "from collections import namedtuple\n",
    "from dataclasses import dataclass\n",
    "import functools\n",
    "from pprint import pprint\n",
    "\n",
    "rc('font',**{'family': 'serif', 'size': 19})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "path_to_results = os.path.normpath(os.path.join(parent_dir, \"archive\"))\n",
    "print(path_to_results)\n",
    "working_dir = os.path.normpath(os.path.join(parent_dir, \"working\"))\n",
    "data = parsers.main(path_to_results, working_dir=working_dir)\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CpuEntry = namedtuple('CpuEntry', 'time cpu')\n",
    "  \n",
    "def extract_intervals(iterable, predicate):\n",
    "    first_matched = None\n",
    "    last = None\n",
    "    for (idx, item) in enumerate(iterable):\n",
    "        if predicate(item):\n",
    "            last = idx\n",
    "            if first_matched is None:\n",
    "                first_matched = idx\n",
    "        else:\n",
    "            if first_matched is not None:\n",
    "                interval = portion.closed(first_matched, idx)\n",
    "                first_matched = None\n",
    "                last = None\n",
    "                yield interval\n",
    "    if first_matched is not None and last is not None:\n",
    "        yield portion.closed(first_matched, last)\n",
    "\n",
    "\n",
    "def get_load_interval(host: parsers.TestHost, sampling_period=0.1, min_length: int=5, load_lower_bound=0.6) -> portion.Interval:\n",
    "    load_interval_lists = []\n",
    "\n",
    "    containers = host.containers()\n",
    "    if not containers:\n",
    "        return None\n",
    "\n",
    "    for container in host.containers():\n",
    "        # Normalize entries from radvisor and moby\n",
    "        entries = []\n",
    "        if container.radvisor:\n",
    "            entries.extend(CpuEntry(time=entry.read, cpu=entry.cpu.total) for entry in container.radvisor[0].values())\n",
    "        elif container.moby:\n",
    "            entries.extend(CpuEntry(time=entry.read, cpu=entry.cpu.total) for entry in container.moby)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Calculate the CPU percentages from the times by using the CPU time/timestamp deltas\n",
    "        interval_zipped_lter = zip(\n",
    "            find_deltas([entry.cpu for entry in entries]),\n",
    "            find_deltas([entry.time for entry in entries]),\n",
    "            entries[1:])\n",
    "        utilization_entries = [CpuEntry(time=entry.time / 1E6, cpu=float(c) / t)\n",
    "            for (c, t, entry) in interval_zipped_lter]\n",
    "\n",
    "        # Sample the CPU utilization\n",
    "        times = [entry.time for entry in utilization_entries]\n",
    "        cpus = [entry.cpu for entry in utilization_entries]\n",
    "        min_time = min(times)\n",
    "        max_time = max(times)\n",
    "        sampling_period_ms = sampling_period * 1E3\n",
    "        sampling_intervals = pd.interval_range(\n",
    "            start=min_time, end=max_time, freq=sampling_period_ms)\n",
    "        cpu_df = pd.DataFrame({'cpu': cpus, 'time': times})\n",
    "        cpu_df['sampling_intervals'] = pd.cut(\n",
    "            x=cpu_df['time'], bins=sampling_intervals, include_lowest=True)\n",
    "        cpu_df = cpu_df.groupby('sampling_intervals').mean()\n",
    "        sampled_entries = [CpuEntry(cpu=row[\"cpu\"], time=row[\"time\"]) for idx, row in cpu_df.iterrows() if row[\"cpu\"] > 0]\n",
    "        \n",
    "        # Perform aggregation on measurements\n",
    "        def make_time_intervals(predicate):\n",
    "            idle_index_intervals = list(extract_intervals(sampled_entries, predicate))\n",
    "            return [portion.closed(sampled_entries[i.lower].time, sampled_entries[i.upper].time)\n",
    "                for i in idle_index_intervals]\n",
    "        \n",
    "        load_intervals = [interval for interval in make_time_intervals(\n",
    "            lambda e: e.cpu >= load_lower_bound) if interval.upper - interval.lower >= min_length - 1]\n",
    "        load_interval_lists.append(load_intervals)\n",
    "\n",
    "    # Find universal intersections of intervals\n",
    "    def combine_interval_lists(a, b):\n",
    "        combined_product_intervals = (i & j for i in a for j in b)\n",
    "        return [interval for interval in combined_product_intervals if not interval.empty]\n",
    "\n",
    "    load_intervals = functools.reduce(lambda a, b: combine_interval_lists(a, b),\n",
    "        load_interval_lists, portion.open(-portion.inf, portion.inf))\n",
    "\n",
    "    # Take union of all universally intersected intervals\n",
    "    return functools.reduce(lambda i1, i2: i1 | i2, load_intervals, portion.empty())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "test = \"i-rc-100\"\n",
    "best_lower_threshold = None\n",
    "# for lower in np.linspace(0, 1)\n",
    "for host in data[test].replicas[1].hosts.values():\n",
    "    result = get_load_interval(host)\n",
    "    if result is not None:\n",
    "        pprint((host.replica_id, host.id))\n",
    "        pprint(result)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_threshold_ts_intervals(host: parsers.TestHost, min_length: int=8, cpu_threshold: float=10, lower_threshold: bool=True) -> List[List[float]]:\n",
    "    cpu_avg = aggregate_cpu(host, sampling_period=1.0)\n",
    "\n",
    "    runs = []\n",
    "    current_run = None\n",
    "    for _, row in cpu_avg.iterrows():\n",
    "        cpu = row['cpu']\n",
    "        if (lower_threshold and cpu > cpu_threshold) or (not lower_threshold and cpu < cpu_threshold):\n",
    "            if not current_run:\n",
    "                current_run = []\n",
    "            current_run.append(row['time'])\n",
    "        else:\n",
    "            if current_run:\n",
    "                runs.append(current_run)\n",
    "                current_run = None\n",
    "    if current_run:\n",
    "        runs.append(current_run)\n",
    "    runs = [r for r in runs if len(r) > min_length]\n",
    "    intervals = [(r[0], r[-1]) for r in runs]\n",
    "    return intervals\n",
    "\n",
    "\n",
    "def describe_intervals(test: parsers.Test, top=0.10, cpu_threshold=50, idle_cpu_threshold=30) -> List[str]:\n",
    "    output = []\n",
    "    output.append(f\"==== {test.id} ====\")\n",
    "    # First, describe all intervals for the test\n",
    "    hosts = flatten(replica.hosts.values() for replica in test.replicas)\n",
    "    all_host_intervals = [host_collection_intervals(host) for host in hosts]\n",
    "    all_container_intervals = flatten(all_host_intervals)\n",
    "    all_intervals = flatten(all_container_intervals)\n",
    "    intervals, _ = zip(*all_intervals)\n",
    "    intervals_df = pd.DataFrame({'Read deltas (ms)': intervals})\n",
    "    output.append(str(intervals_df.describe(include='all')))\n",
    "\n",
    "    # Second, describe top percentage of intervals\n",
    "    top_percent = []\n",
    "    for container_list in all_container_intervals:\n",
    "        container_intervals, _ = zip(*container_list)\n",
    "        limit = np.quantile(container_intervals, 1 - top)\n",
    "        top_percent.extend(i for i in container_intervals if i > limit)\n",
    "    top_percent_df = pd.DataFrame({f'Top {top*100:.1f}% container read deltas (ms)': top_percent})\n",
    "    output.append(str(top_percent_df.describe(include='all')))\n",
    "\n",
    "    # Third, describe all intervals under load\n",
    "    under_load = []\n",
    "    for host, host_intervals in zip(hosts, all_host_intervals):\n",
    "        threshold_intervals = cpu_threshold_ts_intervals(host, cpu_threshold=cpu_threshold)\n",
    "        for container_list in host_intervals:\n",
    "            for interval, timestamp in container_list:\n",
    "                for lower, upper in threshold_intervals:\n",
    "                    if lower <= timestamp <= upper:\n",
    "                        under_load.append(interval)\n",
    "                        break\n",
    "    under_load_df = pd.DataFrame({f'Read deltas undder load (> {cpu_threshold:.1f}% CPU) (ms)': under_load})\n",
    "    output.append(str(under_load_df.describe(include='all')))\n",
    "\n",
    "    # Fourth, describe all intervals at idle\n",
    "    at_idle = []\n",
    "    for host, host_intervals in zip(hosts, all_host_intervals):\n",
    "        threshold_intervals = cpu_threshold_ts_intervals(host, cpu_threshold=idle_cpu_threshold, lower_threshold=False)\n",
    "        for container_list in host_intervals:\n",
    "            for interval, timestamp in container_list:\n",
    "                for lower, upper in threshold_intervals:\n",
    "                    if lower <= timestamp <= upper:\n",
    "                        at_idle.append(interval)\n",
    "                        break\n",
    "    at_idle_df = pd.DataFrame({f'Read deltas at idle (< {idle_cpu_threshold:.1f}% CPU) (ms)': at_idle})\n",
    "    output.append(str(at_idle_df.describe(include='all')))\n",
    "    output.append(f\"=================\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "tests = [\"d-rc-50\", \"d-rc-100\", \"d-mc-50\", \"d-mc-100\", \"i-rc-50\", \"i-rc-100\", \"i-mc-50\", \"i-mc-100\", \"ii-rc-s\", \"ii-rc-b\", \"ii-mc-s\", \"ii-mc-b\"]\n",
    "num = len(tests)\n",
    "done = 0\n",
    "with Pool(cpu_count()) as pool:\n",
    "    for output in pool.imap_unordered(describe_intervals, (data[test] for test in tests)):\n",
    "        print(\"\\n\".join(output))\n",
    "        print(f\"{done+1}/{num} done\")\n",
    "        done += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitvenvvenvd993a90e9781469fa9c047e2d4ffee11",
   "display_name": "Python 3.8.2 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}