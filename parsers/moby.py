"""
Script to parse modified Moby (docker engine) container stat logs
"""

__author__ = "Joseph Azevedo"
__version__ = "1.0"

import numpy as np
import pandas as pd
from dateutil import parser
from collections import OrderedDict
import glob, os, json, csv, argparse


DESCRIPTION = "Script to parse modified Moby (docker engine) container stat logs"


def in_t(val):
    if val is not None and len(val) > 0:
        return int(val)
    return 0


class DataClass:
    def __getattr__(self, attr):
        try:
            return getattr(self, f"_{attr}")
        except AttributeError:
            pass


class NetworkEntry(DataClass):
    """
    Network stats from Moby log entries
    """

    def __init__(self, str):
        rx, tx = str.split("|")
        self._rx = NetworkDirectionStats(rx)
        self._tx = NetworkDirectionStats(tx)


class NetworkDirectionStats(DataClass):
    """
    Network stats from Moby log entries for a single direction (tx/rx)
    """

    def __init__(self, raw):
        num_bytes, packets, errors, dropped = raw.split(" ")
        self._bytes = in_t(num_bytes)
        self._packets = in_t(packets)
        self._errors = in_t(errors)
        self._dropped = in_t(dropped)


class BlkioEntry(DataClass):
    """
    Blkio Linux stats from Moby log entries
    """

    def __init__(self, raw):
        major, minor, value, op = raw.split(" ")
        self._major = in_t(major)
        self._minor = in_t(minor)
        self._value = in_t(value)
        self._op = op


class CpuUsage(DataClass):
    """
    CPUUsage Linux stats from Moby log entries
    """

    def __init__(self, row):
        self._total = in_t(row["cpu_stats.cpu_usage.total_usage"])
        self._percpu = [in_t(cpu.strip()) for cpu in
            row["cpu_stats.cpu_usage.percpu_usage"].split(',')]
        self._kernel = in_t(row["cpu_stats.cpu_usage.usage_in_kernelmode"])
        self._user = in_t(row["cpu_stats.cpu_usage.usage_in_usermode"])
        self._system_usage = in_t(row["cpu_stats.system_cpu_usage"])
        self._online_cpus = in_t(row["cpu_stats.online_cpus"])
        self._throttling_periods = in_t(row["cpu_stats.throttling_data.periods"])
        self._throttled_periods = in_t(row["cpu_stats.throttling_data.throttled_periods"])
        self._throttled_time = in_t(row["cpu_stats.throttling_data.throttled_time"])


class Memory(DataClass):
    """
    Memory Linux stats from Moby log entries
    """

    def __init__(self, row):
        self._usage = in_t(row["memory_stats.usage"])
        self._max_usage = in_t(row["memory_stats.max_usage"])
        self._stats = json.loads(row["memory_stats.stats"])
        self._failcnt = in_t(row["memory_stats.failcnt"])
        self._limit = in_t(row["memory_stats.limit"])


class Blkio(DataClass):
    """
    Blkio Linux stats from Moby log entries
    """

    def __init__(self, row):
        self._service_bytes = parse_blkio(row["blkio_stats.io_service_bytes_recursive"])
        self._serviced = parse_blkio(row["blkio_stats.io_serviced_recursive"])
        self._queue = parse_blkio(row["blkio_stats.io_queue_recursive"])
        self._service_time = parse_blkio(row["blkio_stats.io_service_time_recursive"])
        self._wait_time = parse_blkio(row["blkio_stats.io_wait_time_recursive"])
        self._merged = parse_blkio(row["blkio_stats.io_merged_recursive"])
        self._time = parse_blkio(row["blkio_stats.io_time_recursive"])
        self._sectors = parse_blkio(row["blkio_stats.sectors_recursive"])


class PidsStats(DataClass):
    """
    Pids Linux stats from Moby log entries
    """

    def __init__(self, row):
        self._current = in_t(row["pids_stats.current"])
        self._limit= in_t(row["pids_stats.limit"])


class LogEntry(DataClass):
    """
    A modified Docker engine (Moby) log entry, generated by the
    stats collector in CSV mode
    """

    def __init__(self, row, entries=None):
        """
        Initializes and parses a LogEntry
        Note: discards all statistics that are only populated by moby on Windows
        """

        self._read = in_t(row["read"])
        self._preread = in_t(row["preread"])
        self._name = row["name"]
        self._id = row["id"]
        self._cpu = CpuUsage(row)
        self._memory = Memory(row)
        self._pids = PidsStats(row)
        self._blkio = Blkio(row)
        self._networks = {key: NetworkEntry(entry) for key, entry in
            json.loads(row["networks"]).items()}

        # Try to resolve pre-read statistics
        self._pre = None
        if entries is not None:
            if self._preread in entries:
                pre_entry = entries[self._preread]
                if pre_entry is not None:
                    self._pre = pre_entry


def parse_blkio(raw):
    """
    Parses a Blkio entry array
    """

    split = [entry.strip() for entry in raw.split(",")]
    return [BlkioEntry(entry) for entry in split if len(entry.split(" ")) == 4]


def main(filename):
    """
    Loads an output file from modified moby into an ordered dictionary
    of read timestamp (int) -> LogEntry in the order of logging
    """

    entries = OrderedDict()
    csv_reader = csv.DictReader(filename) 

          # skip header row
    next(csv_reader)

    for row in csv_reader:
        entry = LogEntry(dict(row), entries=entries)
        entries[entry.read] = entry
    return entries